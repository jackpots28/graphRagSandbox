{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-04T03:46:41.101591Z",
     "start_time": "2024-09-04T03:44:08.059731Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Install some packages\n",
    "%pip install langchain_community langchain_text_splitters langchain_core langchain neo4j sentence_transformers"
   ],
   "id": "1f6aa2b53283cef5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain_community in /home/simsjo/.virtualenvs/intro_to_autoencoders/lib/python3.10/site-packages (0.2.16)\r\n",
      "Requirement already satisfied: langchain_text_splitters in /home/simsjo/.virtualenvs/intro_to_autoencoders/lib/python3.10/site-packages (0.2.4)\r\n",
      "Requirement already satisfied: langchain_core in /home/simsjo/.virtualenvs/intro_to_autoencoders/lib/python3.10/site-packages (0.2.38)\r\n",
      "Requirement already satisfied: langchain in /home/simsjo/.virtualenvs/intro_to_autoencoders/lib/python3.10/site-packages (0.2.16)\r\n",
      "Requirement already satisfied: neo4j in /home/simsjo/.virtualenvs/intro_to_autoencoders/lib/python3.10/site-packages (5.24.0)\r\n",
      "Collecting sentence_transformers\r\n",
      "  Obtaining dependency information for sentence_transformers from https://files.pythonhosted.org/packages/58/4b/922436953394e1bfda05e4bf1fe0e80f609770f256c59a9df7a9254f3e0d/sentence_transformers-3.0.1-py3-none-any.whl.metadata\r\n",
      "  Using cached sentence_transformers-3.0.1-py3-none-any.whl.metadata (10 kB)\r\n",
      "Requirement already satisfied: PyYAML>=5.3 in /home/simsjo/.virtualenvs/intro_to_autoencoders/lib/python3.10/site-packages (from langchain_community) (6.0.2)\r\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /home/simsjo/.virtualenvs/intro_to_autoencoders/lib/python3.10/site-packages (from langchain_community) (2.0.33)\r\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /home/simsjo/.virtualenvs/intro_to_autoencoders/lib/python3.10/site-packages (from langchain_community) (3.10.5)\r\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /home/simsjo/.virtualenvs/intro_to_autoencoders/lib/python3.10/site-packages (from langchain_community) (0.6.7)\r\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /home/simsjo/.virtualenvs/intro_to_autoencoders/lib/python3.10/site-packages (from langchain_community) (0.1.111)\r\n",
      "Requirement already satisfied: numpy<2,>=1 in /home/simsjo/.virtualenvs/intro_to_autoencoders/lib/python3.10/site-packages (from langchain_community) (1.26.4)\r\n",
      "Requirement already satisfied: requests<3,>=2 in /home/simsjo/.virtualenvs/intro_to_autoencoders/lib/python3.10/site-packages (from langchain_community) (2.32.3)\r\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /home/simsjo/.virtualenvs/intro_to_autoencoders/lib/python3.10/site-packages (from langchain_community) (8.5.0)\r\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /home/simsjo/.virtualenvs/intro_to_autoencoders/lib/python3.10/site-packages (from langchain_core) (1.33)\r\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /home/simsjo/.virtualenvs/intro_to_autoencoders/lib/python3.10/site-packages (from langchain_core) (24.1)\r\n",
      "Requirement already satisfied: pydantic<3,>=1 in /home/simsjo/.virtualenvs/intro_to_autoencoders/lib/python3.10/site-packages (from langchain_core) (2.8.2)\r\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /home/simsjo/.virtualenvs/intro_to_autoencoders/lib/python3.10/site-packages (from langchain_core) (4.12.2)\r\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /home/simsjo/.virtualenvs/intro_to_autoencoders/lib/python3.10/site-packages (from langchain) (4.0.3)\r\n",
      "Requirement already satisfied: pytz in /home/simsjo/.virtualenvs/intro_to_autoencoders/lib/python3.10/site-packages (from neo4j) (2024.1)\r\n",
      "Collecting transformers<5.0.0,>=4.34.0 (from sentence_transformers)\r\n",
      "  Obtaining dependency information for transformers<5.0.0,>=4.34.0 from https://files.pythonhosted.org/packages/75/35/07c9879163b603f0e464b0f6e6e628a2340cfc7cdc5ca8e7d52d776710d4/transformers-4.44.2-py3-none-any.whl.metadata\r\n",
      "  Using cached transformers-4.44.2-py3-none-any.whl.metadata (43 kB)\r\n",
      "Requirement already satisfied: tqdm in /home/simsjo/.virtualenvs/intro_to_autoencoders/lib/python3.10/site-packages (from sentence_transformers) (4.66.5)\r\n",
      "Collecting torch>=1.11.0 (from sentence_transformers)\r\n",
      "  Obtaining dependency information for torch>=1.11.0 from https://files.pythonhosted.org/packages/9a/bd/4161ae28fb1c388a8ee30ca3aa72cf11ac3016ce62bc9e82c71ce193c410/torch-2.4.0-cp310-cp310-manylinux1_x86_64.whl.metadata\r\n",
      "  Using cached torch-2.4.0-cp310-cp310-manylinux1_x86_64.whl.metadata (26 kB)\r\n",
      "Requirement already satisfied: scikit-learn in /home/simsjo/.virtualenvs/intro_to_autoencoders/lib/python3.10/site-packages (from sentence_transformers) (1.5.1)\r\n",
      "Requirement already satisfied: scipy in /home/simsjo/.virtualenvs/intro_to_autoencoders/lib/python3.10/site-packages (from sentence_transformers) (1.14.1)\r\n",
      "Collecting huggingface-hub>=0.15.1 (from sentence_transformers)\r\n",
      "  Obtaining dependency information for huggingface-hub>=0.15.1 from https://files.pythonhosted.org/packages/b9/8f/d6718641c14d98a5848c6a24d2376028d292074ffade0702940a4b1dde76/huggingface_hub-0.24.6-py3-none-any.whl.metadata\r\n",
      "  Using cached huggingface_hub-0.24.6-py3-none-any.whl.metadata (13 kB)\r\n",
      "Requirement already satisfied: Pillow in /home/simsjo/.virtualenvs/intro_to_autoencoders/lib/python3.10/site-packages (from sentence_transformers) (10.4.0)\r\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/simsjo/.virtualenvs/intro_to_autoencoders/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.4.0)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/simsjo/.virtualenvs/intro_to_autoencoders/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.1)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/simsjo/.virtualenvs/intro_to_autoencoders/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (24.2.0)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/simsjo/.virtualenvs/intro_to_autoencoders/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.1)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/simsjo/.virtualenvs/intro_to_autoencoders/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.0.5)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/simsjo/.virtualenvs/intro_to_autoencoders/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.9.7)\r\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /home/simsjo/.virtualenvs/intro_to_autoencoders/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.22.0)\r\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /home/simsjo/.virtualenvs/intro_to_autoencoders/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\r\n",
      "Collecting filelock (from huggingface-hub>=0.15.1->sentence_transformers)\r\n",
      "  Obtaining dependency information for filelock from https://files.pythonhosted.org/packages/ae/f0/48285f0262fe47103a4a45972ed2f9b93e4c80b8fd609fa98da78b2a5706/filelock-3.15.4-py3-none-any.whl.metadata\r\n",
      "  Using cached filelock-3.15.4-py3-none-any.whl.metadata (2.9 kB)\r\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/simsjo/.virtualenvs/intro_to_autoencoders/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence_transformers) (2024.6.1)\r\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/simsjo/.virtualenvs/intro_to_autoencoders/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain_core) (3.0.0)\r\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/simsjo/.virtualenvs/intro_to_autoencoders/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.0->langchain_community) (0.27.2)\r\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /home/simsjo/.virtualenvs/intro_to_autoencoders/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.0->langchain_community) (3.10.7)\r\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/simsjo/.virtualenvs/intro_to_autoencoders/lib/python3.10/site-packages (from pydantic<3,>=1->langchain_core) (0.7.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /home/simsjo/.virtualenvs/intro_to_autoencoders/lib/python3.10/site-packages (from pydantic<3,>=1->langchain_core) (2.20.1)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/simsjo/.virtualenvs/intro_to_autoencoders/lib/python3.10/site-packages (from requests<3,>=2->langchain_community) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/simsjo/.virtualenvs/intro_to_autoencoders/lib/python3.10/site-packages (from requests<3,>=2->langchain_community) (3.8)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/simsjo/.virtualenvs/intro_to_autoencoders/lib/python3.10/site-packages (from requests<3,>=2->langchain_community) (2.2.2)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/simsjo/.virtualenvs/intro_to_autoencoders/lib/python3.10/site-packages (from requests<3,>=2->langchain_community) (2024.8.30)\r\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/simsjo/.virtualenvs/intro_to_autoencoders/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.0.3)\r\n",
      "Collecting sympy (from torch>=1.11.0->sentence_transformers)\r\n",
      "  Obtaining dependency information for sympy from https://files.pythonhosted.org/packages/c1/f9/6845bf8fca0eaf847da21c5d5bc6cd92797364662824a11d3f836423a1a5/sympy-1.13.2-py3-none-any.whl.metadata\r\n",
      "  Using cached sympy-1.13.2-py3-none-any.whl.metadata (12 kB)\r\n",
      "Collecting networkx (from torch>=1.11.0->sentence_transformers)\r\n",
      "  Obtaining dependency information for networkx from https://files.pythonhosted.org/packages/38/e9/5f72929373e1a0e8d142a130f3f97e6ff920070f87f91c4e13e40e0fba5a/networkx-3.3-py3-none-any.whl.metadata\r\n",
      "  Using cached networkx-3.3-py3-none-any.whl.metadata (5.1 kB)\r\n",
      "Requirement already satisfied: jinja2 in /home/simsjo/.virtualenvs/intro_to_autoencoders/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (3.1.4)\r\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.11.0->sentence_transformers)\r\n",
      "  Obtaining dependency information for nvidia-cuda-nvrtc-cu12==12.1.105 from https://files.pythonhosted.org/packages/b6/9f/c64c03f49d6fbc56196664d05dba14e3a561038a81a638eeb47f4d4cfd48/nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata\r\n",
      "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.11.0->sentence_transformers)\r\n",
      "  Obtaining dependency information for nvidia-cuda-runtime-cu12==12.1.105 from https://files.pythonhosted.org/packages/eb/d5/c68b1d2cdfcc59e72e8a5949a37ddb22ae6cade80cd4a57a84d4c8b55472/nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata\r\n",
      "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.11.0->sentence_transformers)\r\n",
      "  Obtaining dependency information for nvidia-cuda-cupti-cu12==12.1.105 from https://files.pythonhosted.org/packages/7e/00/6b218edd739ecfc60524e585ba8e6b00554dd908de2c9c66c1af3e44e18d/nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata\r\n",
      "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.11.0->sentence_transformers)\r\n",
      "  Obtaining dependency information for nvidia-cudnn-cu12==9.1.0.70 from https://files.pythonhosted.org/packages/9f/fd/713452cd72343f682b1c7b9321e23829f00b842ceaedcda96e742ea0b0b3/nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata\r\n",
      "  Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.11.0->sentence_transformers)\r\n",
      "  Obtaining dependency information for nvidia-cublas-cu12==12.1.3.1 from https://files.pythonhosted.org/packages/37/6d/121efd7382d5b0284239f4ab1fc1590d86d34ed4a4a2fdb13b30ca8e5740/nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata\r\n",
      "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.11.0->sentence_transformers)\r\n",
      "  Obtaining dependency information for nvidia-cufft-cu12==11.0.2.54 from https://files.pythonhosted.org/packages/86/94/eb540db023ce1d162e7bea9f8f5aa781d57c65aed513c33ee9a5123ead4d/nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata\r\n",
      "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.11.0->sentence_transformers)\r\n",
      "  Obtaining dependency information for nvidia-curand-cu12==10.3.2.106 from https://files.pythonhosted.org/packages/44/31/4890b1c9abc496303412947fc7dcea3d14861720642b49e8ceed89636705/nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata\r\n",
      "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.11.0->sentence_transformers)\r\n",
      "  Obtaining dependency information for nvidia-cusolver-cu12==11.4.5.107 from https://files.pythonhosted.org/packages/bc/1d/8de1e5c67099015c834315e333911273a8c6aaba78923dd1d1e25fc5f217/nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata\r\n",
      "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.11.0->sentence_transformers)\r\n",
      "  Obtaining dependency information for nvidia-cusparse-cu12==12.1.0.106 from https://files.pythonhosted.org/packages/65/5b/cfaeebf25cd9fdec14338ccb16f6b2c4c7fa9163aefcf057d86b9cc248bb/nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata\r\n",
      "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=1.11.0->sentence_transformers)\r\n",
      "  Obtaining dependency information for nvidia-nccl-cu12==2.20.5 from https://files.pythonhosted.org/packages/4b/2a/0a131f572aa09f741c30ccd45a8e56316e8be8dfc7bc19bf0ab7cfef7b19/nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata\r\n",
      "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\r\n",
      "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.11.0->sentence_transformers)\r\n",
      "  Obtaining dependency information for nvidia-nvtx-cu12==12.1.105 from https://files.pythonhosted.org/packages/da/d3/8057f0587683ed2fcd4dbfbdfdfa807b9160b809976099d36b8f60d08f03/nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata\r\n",
      "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\r\n",
      "Collecting triton==3.0.0 (from torch>=1.11.0->sentence_transformers)\r\n",
      "  Obtaining dependency information for triton==3.0.0 from https://files.pythonhosted.org/packages/45/27/14cc3101409b9b4b9241d2ba7deaa93535a217a211c86c4cc7151fb12181/triton-3.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata\r\n",
      "  Using cached triton-3.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.3 kB)\r\n",
      "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->sentence_transformers)\r\n",
      "  Obtaining dependency information for nvidia-nvjitlink-cu12 from https://files.pythonhosted.org/packages/a8/48/a9775d377cb95585fb188b469387f58ba6738e268de22eae2ad4cedb2c41/nvidia_nvjitlink_cu12-12.6.68-py3-none-manylinux2014_x86_64.whl.metadata\r\n",
      "  Using cached nvidia_nvjitlink_cu12-12.6.68-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting regex!=2019.12.17 (from transformers<5.0.0,>=4.34.0->sentence_transformers)\r\n",
      "  Obtaining dependency information for regex!=2019.12.17 from https://files.pythonhosted.org/packages/3e/66/04b63f31580026c8b819aed7f171149177d10cfab27477ea8800a2268d50/regex-2024.7.24-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\r\n",
      "  Using cached regex-2024.7.24-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\r\n",
      "Collecting safetensors>=0.4.1 (from transformers<5.0.0,>=4.34.0->sentence_transformers)\r\n",
      "  Obtaining dependency information for safetensors>=0.4.1 from https://files.pythonhosted.org/packages/18/f3/27bf4d7112b194eea2d8401706953080692d37ace1b74b36fcc7234961cd/safetensors-0.4.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\r\n",
      "  Using cached safetensors-0.4.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\r\n",
      "Collecting tokenizers<0.20,>=0.19 (from transformers<5.0.0,>=4.34.0->sentence_transformers)\r\n",
      "  Obtaining dependency information for tokenizers<0.20,>=0.19 from https://files.pythonhosted.org/packages/40/4f/eb78de4af3b17b589f43a369cbf0c3a7173f25c3d2cd93068852c07689aa/tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\r\n",
      "  Using cached tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\r\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/simsjo/.virtualenvs/intro_to_autoencoders/lib/python3.10/site-packages (from scikit-learn->sentence_transformers) (1.4.2)\r\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/simsjo/.virtualenvs/intro_to_autoencoders/lib/python3.10/site-packages (from scikit-learn->sentence_transformers) (3.5.0)\r\n",
      "Requirement already satisfied: anyio in /home/simsjo/.virtualenvs/intro_to_autoencoders/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain_community) (4.4.0)\r\n",
      "Requirement already satisfied: httpcore==1.* in /home/simsjo/.virtualenvs/intro_to_autoencoders/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain_community) (1.0.5)\r\n",
      "Requirement already satisfied: sniffio in /home/simsjo/.virtualenvs/intro_to_autoencoders/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain_community) (1.3.1)\r\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/simsjo/.virtualenvs/intro_to_autoencoders/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain_community) (0.14.0)\r\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /home/simsjo/.virtualenvs/intro_to_autoencoders/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/simsjo/.virtualenvs/intro_to_autoencoders/lib/python3.10/site-packages (from jinja2->torch>=1.11.0->sentence_transformers) (2.1.5)\r\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy->torch>=1.11.0->sentence_transformers)\r\n",
      "  Obtaining dependency information for mpmath<1.4,>=1.1.0 from https://files.pythonhosted.org/packages/43/e3/7d92a15f894aa0c9c4b49b8ee9ac9850d6e63b03c9c32c0367a13ae62209/mpmath-1.3.0-py3-none-any.whl.metadata\r\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\r\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/simsjo/.virtualenvs/intro_to_autoencoders/lib/python3.10/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain_community) (1.2.2)\r\n",
      "Using cached sentence_transformers-3.0.1-py3-none-any.whl (227 kB)\r\n",
      "Using cached huggingface_hub-0.24.6-py3-none-any.whl (417 kB)\r\n",
      "Downloading torch-2.4.0-cp310-cp310-manylinux1_x86_64.whl (797.2 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m797.2/797.2 MB\u001B[0m \u001B[31m5.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:03\u001B[0m\r\n",
      "\u001B[?25hUsing cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\r\n",
      "Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\r\n",
      "Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\r\n",
      "Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\r\n",
      "Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\r\n",
      "Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\r\n",
      "Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\r\n",
      "Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\r\n",
      "Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\r\n",
      "Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\r\n",
      "Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\r\n",
      "Downloading triton-3.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (209.4 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m209.4/209.4 MB\u001B[0m \u001B[31m7.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hUsing cached transformers-4.44.2-py3-none-any.whl (9.5 MB)\r\n",
      "Downloading regex-2024.7.24-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (776 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m776.5/776.5 kB\u001B[0m \u001B[31m8.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading safetensors-0.4.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (435 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m435.5/435.5 kB\u001B[0m \u001B[31m8.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m3.6/3.6 MB\u001B[0m \u001B[31m8.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hUsing cached filelock-3.15.4-py3-none-any.whl (16 kB)\r\n",
      "Using cached networkx-3.3-py3-none-any.whl (1.7 MB)\r\n",
      "Using cached sympy-1.13.2-py3-none-any.whl (6.2 MB)\r\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\r\n",
      "Using cached nvidia_nvjitlink_cu12-12.6.68-py3-none-manylinux2014_x86_64.whl (19.7 MB)\r\n",
      "Installing collected packages: mpmath, sympy, safetensors, regex, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, networkx, filelock, triton, nvidia-cusparse-cu12, nvidia-cudnn-cu12, huggingface-hub, tokenizers, nvidia-cusolver-cu12, transformers, torch, sentence_transformers\r\n",
      "Successfully installed filelock-3.15.4 huggingface-hub-0.24.6 mpmath-1.3.0 networkx-3.3 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.6.68 nvidia-nvtx-cu12-12.1.105 regex-2024.7.24 safetensors-0.4.4 sentence_transformers-3.0.1 sympy-1.13.2 tokenizers-0.19.1 torch-2.4.0 transformers-4.44.2 triton-3.0.0\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.2.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m24.2\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpython3 -m pip install --upgrade pip\u001B[0m\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-04T03:49:15.026340Z",
     "start_time": "2024-09-04T03:49:15.023560Z"
    }
   },
   "source": [
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_community.document_loaders import Docx2txtLoader\n",
    "from langchain_community.vectorstores import Neo4jVector\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "\n",
    "from langchain_text_splitters import CharacterTextSplitter, RecursiveCharacterTextSplitter, NLTKTextSplitter\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain.chains import RetrievalQAWithSourcesChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "\n",
    "from neo4j import GraphDatabase\n",
    "from neo4j import exceptions\n",
    "\n",
    "# from tqdm.notebook import tqdm\n",
    "# from sentence_transformers import SentenceTransformer\n",
    "from typing import List\n",
    "\n",
    "from pathlib import Path\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from dataclasses import dataclass, field\n",
    "import secrets\n"
   ],
   "outputs": [],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "id": "bf6ead3c53095ed9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-04T03:49:48.342303Z",
     "start_time": "2024-09-04T03:49:47.896033Z"
    }
   },
   "source": [
    "### Setup container image env vars for auth - neo4j graph db\n",
    "\n",
    "# GEN rand password for temp graphDB\n",
    "one_time_password: str = secrets.token_urlsafe(23)\n",
    "\n",
    "os.environ['NEO4J_DRIV_PORT'] = '7687'\n",
    "os.environ['NEO4J_HTTP_PORT'] = '7474'\n",
    "os.environ['NEO4J_USERNAME'] = 'neo4j'\n",
    "os.environ['NEO4J_PASSWORD'] = one_time_password\n",
    "\n",
    "!echo ${NEO4J_DRIV_PORT}\n",
    "!echo ${NEO4J_HTTP_PORT}\n",
    "!echo ${NEO4J_USERNAME}\n",
    "!echo ${NEO4J_PASSWORD}"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7687\r\n",
      "7474\r\n",
      "neo4j\r\n",
      "5jumE8WYf8gQXYi_5Df4TP4Bdo_TiRQ\r\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "id": "1bde8712c3007213",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-04T03:55:11.863543Z",
     "start_time": "2024-09-04T03:55:09.716773Z"
    }
   },
   "source": [
    "### Drop existing graph db completely (rm container) and rebuild from fresh\n",
    "\n",
    "# Pull latest image if none exist - continue without pulling if already present\n",
    "!docker images neo4j:latest | awk 'NR>1{print $1}' | if [[ $_ != \"neo4j:latest\" ]]; then docker pull neo4j:latest; else printf \"NEO4J image present.\\n\"; fi\n",
    "\n",
    "!docker ps -a | grep -ie neo4j | awk '{print $1}' | xargs -I{} docker rm {} -f\n",
    "!docker ps -a | grep -ie neo4j\n",
    "!docker run -d --restart always --publish=${NEO4J_HTTP_PORT}:${NEO4J_HTTP_PORT} --publish=${NEO4J_DRIV_PORT}:${NEO4J_DRIV_PORT} --env NEO4J_AUTH=${NEO4J_USERNAME}/${NEO4J_PASSWORD} neo4j:latest\n",
    "!docker ps -a | grep -ie neo4j"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "latest: Pulling from library/neo4j\r\n",
      "Digest: sha256:6dcf2bdb9cc227325dd99cfb40712d47c746993150e2ce523ca1e1a72521605d\r\n",
      "Status: Image is up to date for neo4j:latest\r\n",
      "docker.io/library/neo4j:latest\r\n",
      "\u001B[1m\r\n",
      "What's Next?\r\n",
      "\u001B[0m  View a summary of image vulnerabilities and recommendations → \u001B[36mdocker scout quickview neo4j:latest\u001B[0m\r\n",
      "2d79abf7ee6a633793a1fe71469ed555e81401b463a99791578ff03a2cf373f6\r\n",
      "2d79abf7ee6a   neo4j:latest                                                                     \"tini -g -- /startup…\"   1 second ago   Up Less than a second       0.0.0.0:7474->7474/tcp, 7473/tcp, 0.0.0.0:7687->7687/tcp   heuristic_swanson\r\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a5a76de1c4c767",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try the embeddings model: msmarco-MiniLM-L-12-v3 or all-mpnet-base-v2 - using sentence-transformers locally\n",
    "# Using a dict to store multiple model references - easier to keep track of things I've tried and whats present\n",
    "ollama_model_library = {\n",
    "    \"smollm\":\"smollm:1.7b\",\n",
    "    \"llama3.1\":\"llama3.1:8b\",\n",
    "    \"all-minilm\":\"all-minilm:l6-v2\",\n",
    "    \"llama3\":\"llama3:latest\",\n",
    "    \"mxbai-embed-large\":\"mxbai-embed-large:latest\",\n",
    "    \"codellama\":\"codellama:13b\"\n",
    "}\n",
    "\n",
    "ollama_emb = OllamaEmbeddings(\n",
    "    model=ollama_model_library['llama3'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef62ea44da5209a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original test documents\n",
    "documents_dictionary_struct = {\n",
    "    \"smartbear\": Path(\"/Volumes/stuff/graphRagSandbox/assets/SmartBear_TOU-10FEB2023.docx\"),\n",
    "    \"shrekmovie\": Path(\"/Volumes/stuff/general_playground/assets/the_entire_shrek_script.txt\"),\n",
    "    \"dantesinferno\": Path(\"/Volumes/stuff/general_playground/assets/dantes_inferno_all_chp.txt\")\n",
    "}\n",
    "\n",
    "# loader = TextLoader(smart_bear_contract)\n",
    "docx_loader = Docx2txtLoader(documents_dictionary_struct[\"smartbear\"])\n",
    "documents = docx_loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ade4020474afb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Created a dataclass incase I reference the same variables for splitter construction - one-stop shop for changing vars during testing\n",
    "@dataclass\n",
    "class RecTxtDataClass:\n",
    "    c_size: int = 120\n",
    "    c_overlap: int = 20\n",
    "    c_separators: List = field(default_factory=lambda: [\"\\n\\n\", \"\\n\", \".\"])\n",
    "    c_len_fun: len = lambda x: len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb1ca60b67ed17",
   "metadata": {},
   "outputs": [],
   "source": [
    "RecTxtObj = RecTxtDataClass()\n",
    "\n",
    "# text_splitter = NLTKTextSplitter(chunk_size=1500, chunk_overlap=20, separator=\". \")\n",
    "# I used a recursive splitter since I wanted to break on paragraph, complete sentence, and single words (but not single chars) - this worked well for legal docs\n",
    "recursive_splitter = RecursiveCharacterTextSplitter(chunk_size=RecTxtObj.c_size, \n",
    "                                                    chunk_overlap=RecTxtObj.c_overlap, \n",
    "                                                    separators=RecTxtObj.c_separators, \n",
    "                                                    length_function=RecTxtObj.c_len_fun)\n",
    "\n",
    "# nltk_docs = text_splitter.split_documents(documents)\n",
    "rec_docs = recursive_splitter.split_documents(documents)\n",
    "rec_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163a7d4546ac5f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_name_only = documents_dictionary_struct[\"smartbear\"].with_suffix(\"\").name\n",
    "\n",
    "for k,v in rec_docs[0]:\n",
    "    \n",
    "    print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32237dfcf4b43ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "URI = f'neo4j://localhost:{os.environ['NEO4J_DRIV_PORT']}'\n",
    "USERNAME = os.environ['NEO4J_USERNAME']\n",
    "PASSWORD = os.environ['NEO4J_PASSWORD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cce50230aedfc06",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = GraphDatabase.driver(URI, auth=(USERNAME, PASSWORD))\n",
    "\n",
    "db = Neo4jVector.from_documents(\n",
    "    rec_docs, ollama_emb, url=URI, username=USERNAME, password=PASSWORD\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65df431ddad02d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_db_index_create: str = f\"CREATE FULLTEXT INDEX text_index IF NOT EXISTS FOR (n:Chunk) ON EACH[n.text]\"\n",
    "graph_db_fulltext_label_query: str = f\"CALL db.index.fulltext.queryNodes(\\\"text_index\\\", \\\".\\\") YIELD node RETURN node.id\"\n",
    "\n",
    "with driver.session() as session:\n",
    "    # session.run(\"CREATE FULLTEXT INDEX text_index IF NOT EXISTS FOR (n:Chunk) ON EACH[n.text]\")\n",
    "    try:\n",
    "        result = session.run(graph_db_fulltext_label_query)\n",
    "    except exceptions.ClientError as e:\n",
    "        print(f\"FULLTEXT INDEX - Not Present\")\n",
    "        print(e)\n",
    "    finally:\n",
    "        session.run(graph_db_index_create)\n",
    "        print(f\"text_index - Created\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd3763197021b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name = \"vector\"\n",
    "keyword_index_name = \"text_index\"\n",
    "search_type = \"hybrid\"\n",
    "\n",
    "# Look at this article in streamlining the graphDB construction and index ingestion into simpler method:\n",
    "# https://medium.com/neo4j/using-langchain-in-combination-with-neo4j-to-process-youtube-playlists-and-perform-q-a-flow-5d245d51a735\n",
    "store = Neo4jVector.from_existing_index(\n",
    "    ollama_emb,\n",
    "    url=URI,\n",
    "    username=USERNAME,\n",
    "    password=PASSWORD,\n",
    "    index_name=index_name,\n",
    "    keyword_index_name=keyword_index_name,\n",
    "    search_type=search_type,\n",
    ")\n",
    "\n",
    "retriever = store.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9066c400fc7cf971",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This prompt worked well for submitting lists of lookup phrases and receiving lists of found verified matches\n",
    "prompt_template = \"\"\"You will be give a list of phrases to search for within the context provided. Strictly follow these outlined rules when producing answers:\n",
    "1. If you don't know the answer, don't try to make up an answer. Just answer with NULL.\n",
    "2. If you find the answer, only respond with a list of complete sentences that pertain to the provided phrases in the following format: [sentence1, sentence2, ...]\n",
    "\n",
    "This document pertains to: {context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Answer:\n",
    "\n",
    "{summaries}\"\"\"\n",
    "\n",
    "PROMPT = PromptTemplate(\n",
    "    template=prompt_template, input_variables=[\"context\", \"question\", \"summaries\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8563bd02fc1fd0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "context: str = doc_name_only\n",
    "# question: str = input(f\"What is your question about {context}\")\n",
    "\n",
    "raw_question_list: list = [\n",
    "    'customer name apart of the contract',\n",
    "    'contract effective date',\n",
    "    'required notice time before non-renewal',\n",
    "]\n",
    "\n",
    "formatted_question_list: str = \"[\"\n",
    "for iter_n in range(len(raw_question_list)):\n",
    "    if iter_n < len(raw_question_list)-1:\n",
    "        formatted_question_list += str(raw_question_list[iter_n])+\", \"\n",
    "    else:\n",
    "        formatted_question_list += str(raw_question_list[iter_n])+\"]\"\n",
    "\n",
    "# formatted_question_list: str = f\"[{raw_question_list[0]}, {raw_question_list[1]}, {raw_question_list[2]}]\"\n",
    "\n",
    "memory = ConversationBufferMemory(memory_key=\"history\", \n",
    "                                  input_key=\"question\", \n",
    "                                  output_key='answer', \n",
    "                                  return_messages=True,\n",
    "                                  )\n",
    "\n",
    "llm = ChatOllama(model=\"llama3:latest\", \n",
    "                 temperature=0.0,\n",
    "                 format=\"json\",\n",
    "                 )\n",
    "\n",
    "chain = RetrievalQAWithSourcesChain.from_chain_type(\n",
    "    llm,\n",
    "    chain_type=\"stuff\", \n",
    "    retriever=retriever, \n",
    "    chain_type_kwargs={ \"prompt\": PROMPT },\n",
    "    memory=memory,\n",
    ")\n",
    "\n",
    "response = chain.invoke({'context': context, 'question': formatted_question_list})\n",
    "print(f\"Query list: {response['question']}\\nAnswer list: {response['answer']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd41beb291ddf22b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
